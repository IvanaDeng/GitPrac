{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvanaDeng/GitPrac/blob/main/Week-07-Exercise01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nhnOcx-H4r7"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?export=view&id=1DXUVHxd4t15mfuqMgMCLnsP4jWVI5EWz)\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "© 2022 Copyright The University of New South Wales - CRICOS 00098G\n",
        "\n",
        "**Author**: Oscar Perez-Concha: o.perezconcha@unsw.edu.au\n",
        "\n",
        "**Contributors/Co-authors**: Marta Fredes-Torres and Zhisheng (Sandy) Sa."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 7: Artificial Neural Networks / Deep Learning\n",
        "# Exercise 01:\n",
        "\n",
        "\n",
        "# 1. Introduction\n",
        "\n",
        "In this exercise, we will build our first dense neural network using Keras. Exciting!\n",
        "\n",
        "\n",
        "## 1.1. Aims of the Exercise:\n",
        "\n",
        "1. This is an introduction to Artificial Neural Networks / Deep Learning.\n",
        "2. We will use Keras, a high-level API built on top of Tensorflow.\n",
        "It aligns with all of the learning outcomes of our course:\n",
        "\n",
        "1.\tDistinguish a range of task specific machine learning techniques appropriate for Health Data Science.\n",
        "2.\tDesign machine learning tasks for Health Data Science scenarios.\n",
        "\n",
        "\n",
        "## 1.2. Jupyter Notebook Intructions\n",
        "1. Read the content of each cell.\n",
        "2. Where necessary, follow the instructions that are written in each cell.\n",
        "3. Run/Execute all the cells that contain Python code sequentially (one at a time), using the \"Run\" button.\n",
        "4. For those cells in which you are asked to write some code, please write the Python code first and then execute/run the cell.\n",
        "\n",
        "## 1.3. Tips\n",
        "1. Run all the cells in sequence (one at a time), using the \"Run\" button.\n",
        "2. To edit this notebook, just double-click in each cell. Choose between \"Code\" cell or text \"Markdown\" cell in the combo-box above.\n",
        "3. If you want to save your notebook, please go File->Save a copy on Drive/GitHub.\n",
        "4. To clean the content of all cells and re-start Notebook, please go to Edit->Clear all outputs then Runtime->Restart runtime\n",
        "\n",
        "Follow the instructions given and if you have any questions, please use the **Comments section** in **Open Learning**."
      ],
      "metadata": {
        "id": "p3XWRVcUWeRw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgVK8dQpH4r_"
      },
      "source": [
        "# 2. Docstring:\n",
        "\n",
        "Create a docstring with the variables and constants that you will use in this exercise (data dictionary) and the purpose of your program. It is expected that you choose informative variable names and document your program (both docstrings and comments)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS2pdi4pH4sA"
      },
      "source": [
        "<b> Write the answer here:</b>\n",
        "\n",
        "#####################################################################################################################\n",
        "\n",
        "(double-click here)\n",
        "\n",
        "\n",
        "#####################################################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk6AMHscH4sB"
      },
      "source": [
        "# 3. Reading and Manipulating Malaria Cell Images Data set\n",
        "\n",
        "<font color=green><b> Aim/Goal</b>: In this week, we will detect malaria cells that are parasitized with ANN (Artificial Neural Networks) algorithms. </font> We will use two sets of data that contain images of infected and uninfected cells. More information see[Tensorflow Malaria](https://www.tensorflow.org/datasets/catalog/malaria) and [NLM - Malaria Data](https://lhncbc.nlm.nih.gov/LHC-research/LHC-projects/image-processing/malaria-datasheet.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TPqCNwUGH4sB",
        "outputId": "85f5e252-021e-4fba-fde2-b92437ceb212",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing:  {'lime', 'grid', 'shap'}\n"
          ]
        }
      ],
      "source": [
        "# check required libraries are installed if not calling system to install\n",
        "import sys\n",
        "import subprocess\n",
        "import pkg_resources\n",
        "\n",
        "required = {'numpy', 'pandas', 'plotnine', 'matplotlib', 'seaborn',\n",
        "            'grid', 'lime', 'shap', 'scikit-learn', 'tensorflow'}\n",
        "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
        "missing = required - installed\n",
        "\n",
        "if missing:\n",
        "    print('Installing: ', missing)\n",
        "    python = sys.executable\n",
        "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n",
        "# delete unwanted variables\n",
        "del required\n",
        "del installed\n",
        "del missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ogcb9t1EH4sD",
        "outputId": "e6dea7ab-f949-4f51-fccf-2e5e9dfc2801",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "import warnings; warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wulnY15jH4sD",
        "outputId": "9e07aae1-20b9-4cdd-c2d4-91b5ae802db4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p4jKCNk1H4sE",
        "outputId": "16dd045b-6370-4cfa-cba2-9cdf73e0a866",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "# We do not need to run this cell if you are not running this notebook in Google Colab\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import drive # import drive from Gogle colab\n",
        "    root = '/content/drive'     # default location for the drive\n",
        "    # print(root)                 # print content of ROOT (Optional)\n",
        "    drive.mount(root)\n",
        "else:\n",
        "    print('Not running on CoLab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO04HmE3H4sF"
      },
      "source": [
        "If you are running this notebook in Google Colab, you must define your project paths. In this case, define your `project_path`. Otherwise, the model output will be lost after you close the session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VLgjMv5_H4sH"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    # EDIT THE PROJECT PATH IF DIFFERENT WITH YOUR ONE\n",
        "    # T\n",
        "    project_path = Path(root) / 'MyDrive' / 'HDAT9500' / 'week07'\n",
        "\n",
        "    # OPTIONAL - set working directory according to your google drive project path\n",
        "    # import os\n",
        "    # Change directory to the location defined in project_path\n",
        "    # os.chdir(project_path)\n",
        "else:\n",
        "    project_path = Path()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNqS2ujKH4sH"
      },
      "source": [
        "## 3.1 Dataset\n",
        "The original Malaria cell image dataset can be downloaded from [Kaggle](https://www.kaggle.com/datasets/iarunava/cell-images-for-detecting-malaria?resource=download)\n",
        "\n",
        "The image dataset need to processed into array before feeding into ANN. Data preparation code are stored in a separate notebook called **Week-05-data-preparation.ipynnb**\n",
        "\n",
        "Now let's have a look what these images look like first:\n",
        "\n",
        "**The parasitized images**\n",
        "\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1a2Qopc2ejiW3RkpLOCIge4b42tYIEaqq)\n",
        "\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1cEJxQmXAcgc0f8Mo8hSsSO9s5m183Qil)\n",
        "\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1BM-l4FO1ClvtjqA9D397ZDwjkrit8bYn)\n",
        "\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1CZJitEjxDcbtKzOSXvv1LiETwxQloLEi)\n",
        "\n",
        "**The uninfected images**\n",
        "\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1ak0EI4p5w387kxmeLuUuIr5MTL6kY5se)\n",
        "\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1HB8wJyfrFTSTijmck4nsS90iMUQhDpaI)\n",
        "\n",
        "![alt text](https://drive.google.com/uc?export=view&id=11Xvt0uCFlT3r7s7Bj6d8a99z29ZkJgQJ)\n",
        "\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1a0UdWFtY7FxUrlXgVGTqoI-qIdEQZRsI)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGn71_3xH4sI"
      },
      "source": [
        "**Now let's load the processed data**\n",
        "\n",
        "The images were resized to (64x64) and transformed into a 1D vector then saved as a data list called 'data'. The label of the images was saved in a separate data list called 'labels' in a compressed data file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n4oPDtHZH4sI"
      },
      "outputs": [],
      "source": [
        "data_path = Path(project_path) / 'data' / 'malaria_img.npz'\n",
        "with np.load(data_path) as img:\n",
        "    data = img['data']\n",
        "    labels = img['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OvWN_Es_H4sI",
        "outputId": "1755771a-2a29-4feb-e2c2-3b9993c18e44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cells : (27558, 12288) | labels : (27558,)\n"
          ]
        }
      ],
      "source": [
        "# Printing the shape of the data list and labels\n",
        "print('Cells : {} | labels : {}'.format(data.shape , labels.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yxl4xLkH4sJ"
      },
      "source": [
        "## 3.3 Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWP27ph-H4sJ"
      },
      "source": [
        "It is <font color=purple>**very important to scale**</font> our features when we use ANNs. In this particular example, all the features are already in the same scale because we are dealing with pixels whose values are between [0,1].\n",
        "\n",
        "Therefore, we are not going to scale for that reason.  \n",
        "\n",
        "But when dealing with data that are not scaled, bear in mind that we should use a pipeline as we did in the past weeks in order to scale our features before being fed to the ANN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BNnTckZoH4sJ",
        "outputId": "27056baf-f328-421d-cdf0-4ee98beaf867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No data smaller than 0: []\n",
            "No data higher than 1: []\n",
            "print data higher than 0: [0. 0. 0. ... 0. 0. 0.]\n",
            "print data higher than 0.1: [0.10058977 0.8095167  0.47208562 ... 0.19573687 0.20504151 0.20645538]\n",
            "print data higher than 0.5: [0.8095167 0.5582415 0.8116766 ... 0.7546219 0.7907126 0.7961967]\n",
            "print data higher than 0.9: [0.90121305 0.90391296 0.90254384 ... 0.90535814 0.9083625  0.90008044]\n"
          ]
        }
      ],
      "source": [
        "# Sanity check that data values are between [0,1]\n",
        "print('No data smaller than 0:', data[data<0])\n",
        "print('No data higher than 1:', data[data>1])\n",
        "\n",
        "print('print data higher than 0:', data[data>=0])\n",
        "print('print data higher than 0.1:', data[data>=0.1])\n",
        "print('print data higher than 0.5:', data[data>=0.5])\n",
        "print('print data higher than 0.9:', data[data>=0.9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IVWnGTWAH4sK"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size = 0.2, random_state = 0, stratify = labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Hl8wXbmkH4sK",
        "outputId": "90ad03d3-fdf7-4587-b151-a969b26e7ea9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SHAPE OF TRAINING IMAGE DATA : (22046, 12288)\n",
            "SHAPE OF TESTING IMAGE DATA : (5512, 12288)\n",
            "SHAPE OF TRAINING LABELS : (22046,)\n",
            "SHAPE OF TESTING LABELS : (5512,)\n"
          ]
        }
      ],
      "source": [
        "# Sanity Check\n",
        "print(f'SHAPE OF TRAINING IMAGE DATA : {X_train.shape}')\n",
        "print(f'SHAPE OF TESTING IMAGE DATA : {X_test.shape}')\n",
        "print(f'SHAPE OF TRAINING LABELS : {y_train.shape}')\n",
        "print(f'SHAPE OF TESTING LABELS : {y_test.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNa7F-3QH4sM"
      },
      "source": [
        "# 4. Our first ANN using Keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "g4Fy1uJoH4sM"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Flatten\n",
        "from keras import backend as K\n",
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFgIKLxvH4sN"
      },
      "source": [
        "### <font color='brown'> Question 1: Go to the section titled <b>Creating the model using the Sequential API</b> in the book:</font>\n",
        "\n",
        "<font color='brown'>a. Write code to initialise ANN. </font>\n",
        "\n",
        "<font color='brown'>b. Create a first hidden layer with 16 nodes and a relu activation function. Use the function `add` and  the argument `input_dim` since the data have been flatten out already (see the data prepartion notebook).</font>\n",
        "\n",
        "<font color='brown'>c. Create a second hidden layer with 16 nodes and a relu activation function. Use the function `add`.</font>\n",
        "\n",
        "<font color='brown'>d. Add output layer: Using the functions \"add\" and \"dense\". What activation function would you use and why? </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='green'>Help: </font>\n",
        "\n",
        "1. [Additional information about how to use the function `add` by using the argument `input_dim`](https://keras.io/getting-started/sequential-model-guide/)\n",
        "2. [Function `dense`](https://keras.io/layers/core/#dense)\n",
        "3. [Activation functions other than relu](https://keras.io/api/layers/activations/)\n",
        "4. [Read here how to use the function `add` by using the argument `input_dim`](https://keras.io/getting-started/sequential-model-guide/)\n",
        "5.[Merging layers](https://keras.io/layers/merge/#add_1)"
      ],
      "metadata": {
        "id": "cpmNR5s4xWOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write Python Code here:\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(16, activation = 'relu', input_dim = 12288))\n",
        "model.add(Dense(16, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "Rbjd76Lj0Sqi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "model.weights"
      ],
      "metadata": {
        "id": "7gSSSbzwGhQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0pEVTfYH4sS"
      },
      "source": [
        "### <font color='brown'> Question 2: Compile our model.  Use gradient descent (\"adam\", for example) for the optimizer, \"binary_crossentropy\" as the loss function, and accuracy as our metric.  </font>\n",
        "\n",
        "a. [Loss functions in Keras](https://keras.io/api/losses/)\n",
        "\n",
        "b. [Metrics in Keras](https://keras.io/api/metrics/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "fFP7jHpzH4sT"
      },
      "outputs": [],
      "source": [
        "# Write Python Code here:\n",
        "# Compiling the ANN\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer= 'adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhmXfrwJH4sU"
      },
      "source": [
        "### <font color='brown'> Question 3: Fitting the ANN to the Training set. Set the batch_size=100, epochs=150. These hyper-parameters have to be tuned. These numbers have been optimised already. How much accuracy does the model obtain in the training test?</font>\n",
        "<p>\n",
        "<font color='green'>Note: batch_size, epochs can be tuned using GridSearchCV or trial and error. We will tune these parameters in Exercise 2.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_7YnRb2H4sU",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Write Python Code here:\n",
        "history = model.fit(X_train, y_train, epochs = 150,\n",
        "                    batch_size = 100)\n",
        "# model only obtains 50% accuracy??"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history\n"
      ],
      "metadata": {
        "id": "V1Uuq05vOoXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRI0CyvLH4sV"
      },
      "source": [
        "### <font color='brown'> Question 4: Calculate accuracy, confusion matrix and all the metrics included in classification_report function  </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "eGpOFePbH4sV",
        "outputId": "f6adf570-7b74-4300-b20f-8b37436ed47d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "173/173 [==============================] - 1s 3ms/step - loss: 0.6367 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6366857290267944, 0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Write Python Code here:\n",
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqeTQrFUH4sW"
      },
      "source": [
        "### <font color='brown'> Question 5: Write your conclusions about the performance and potential use of this classifier. </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe0VQMC1H4sW"
      },
      "source": [
        "<b> Write answer here:</b>\n",
        "#####################################################################################################################\n",
        "\n",
        "(Double-click here)\n",
        "\n",
        "\n",
        "#####################################################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpGxOdQ2WLN7"
      },
      "source": [
        "© 2022 Copyright The University of New South Wales - CRICOS 00098G"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Chapter06-Exercise01.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.7.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}